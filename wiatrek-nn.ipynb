{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gutenberg_preamble(text):\n",
    "    try:\n",
    "        return text[text.index(\"***\", text.index(\"START OF THIS PROJECT GUTENBERG\"))+3:]\n",
    "    except:\n",
    "        return text[text.index(\"***\", text.index(\"START OF THE PROJECT GUTENBERG\"))+3:]\n",
    "    \n",
    "def remove_gutenberg_postscript(text):\n",
    "    try:\n",
    "        return text[:text.index(\"***\", text.index(\"END OF THE PROJECT GUTENBERG\"))-3]\n",
    "    except:\n",
    "        return text[:text.index(\"***\", text.index(\"END OF THIS PROJECT GUTENBERG\"))-3]\n",
    "    \n",
    "def get_label(file_loc: str) -> int:\n",
    "    science_fiction = 0\n",
    "    horror = 1\n",
    "    adventure = 2\n",
    "    humor = 3\n",
    "    western = 4\n",
    "    mystery = 5\n",
    "    gothic = 6\n",
    "    if 'gothic' in file_loc:\n",
    "        return gothic\n",
    "    if 'western' in file_loc:\n",
    "        return western\n",
    "    if 'mystery' in file_loc:\n",
    "        return mystery\n",
    "    if 'humor' in file_loc:\n",
    "        return humor\n",
    "    if 'adventure' in file_loc:\n",
    "        return adventure\n",
    "    if 'horror' in file_loc:\n",
    "        return horror\n",
    "    if 'scifi' in file_loc:\n",
    "        return science_fiction\n",
    "    \n",
    "def create_by_newline(file_loc: str, df):\n",
    "    new_df = pd.DataFrame()\n",
    "    try:\n",
    "        f = open(file_loc, \"r\")\n",
    "        text = f.read()\n",
    "        text = remove_gutenberg_preamble(text)\n",
    "        text = remove_gutenberg_postscript(text)\n",
    "        arr = text.split('\\n\\n')\n",
    "        arr = [a for a in arr if len(a) > 2]\n",
    "        label = get_label(file_loc)\n",
    "        new_df['text'] = arr\n",
    "        new_df['label'] = label\n",
    "        df = df.append(new_df[5:-3])\n",
    "        return df\n",
    "    except:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./set0/western18.txt',\n",
       " './set0/western19.txt',\n",
       " './set0/western09.txt',\n",
       " './set0/western08.txt',\n",
       " './set0/western05.txt',\n",
       " './set0/western11.txt',\n",
       " './set0/western10.txt',\n",
       " './set0/western04.txt',\n",
       " './set0/western12.txt',\n",
       " './set0/western06.txt',\n",
       " './set0/western07.txt',\n",
       " './set0/western13.txt',\n",
       " './set0/western17.txt',\n",
       " './set0/western03.txt',\n",
       " './set0/western02.txt',\n",
       " './set0/western16.txt',\n",
       " './set0/western00.txt',\n",
       " './set0/western14.txt',\n",
       " './set0/western15.txt',\n",
       " './set0/western01.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on = [join('./set0',f) for f in listdir('./set0') if (isfile(join('./set0', f)) and 'western' in f)]\n",
    "train_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "for file in train_on:\n",
    "    new_df = create_by_newline(file, new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# vectorizing function to able to call on list of tokens\n",
    "lemmatize_words = np.vectorize(wordnet_lemmatizer.lemmatize)\n",
    "\n",
    "\n",
    "for index, i in enumerate(new_df['text']):\n",
    "    tokens = word_tokenize(i)\n",
    "    tokens = [t for t in tokens if t not in string.punctuation]\n",
    "    tokens = [t for t in tokens if t not in nltk_stop_words]\n",
    "    \n",
    "    if(len(tokens) < 1):\n",
    "        continue\n",
    "    lemmatized_text = ' '.join(lemmatize_words(tokens))\n",
    "    new_df.at[index,'text'] = lemmatized_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = new_df[:len(new_df) // 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40953, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 128\n",
    "        self.num_layers = 7\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        epochs, batch_size, seq_length\n",
    "    ):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = new_df\n",
    "        text = train_df['text'].str.cat(sep=' ')\n",
    "        return text.split(' ')\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.seq_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.seq_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, model, epochs, batch_size, seq_length):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        state_h, state_c = model.init_state(seq_length)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, next_words=100):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "    \n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 0, 'loss': 10.45074462890625}\n",
      "{'epoch': 0, 'batch': 1, 'loss': 10.443279266357422}\n",
      "{'epoch': 0, 'batch': 2, 'loss': 10.438493728637695}\n",
      "{'epoch': 0, 'batch': 3, 'loss': 10.430967330932617}\n",
      "{'epoch': 0, 'batch': 4, 'loss': 10.420955657958984}\n",
      "{'epoch': 0, 'batch': 5, 'loss': 10.408860206604004}\n",
      "{'epoch': 0, 'batch': 6, 'loss': 10.407341003417969}\n",
      "{'epoch': 0, 'batch': 7, 'loss': 10.3621826171875}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-642841d99adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DONE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-1c962e7c098c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, model, epochs, batch_size, seq_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/3.0.0_1/libexec/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/3.0.0_1/libexec/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--max-epochs', type=int, default=10)\n",
    "# parser.add_argument('--batch-size', type=int, default=256)\n",
    "# parser.add_argument('--sequence-length', type=int, default=4)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 256\n",
    "seq_length = 4\n",
    "\n",
    "dataset = Dataset(epochs, batch_size, seq_length)\n",
    "model = Model(dataset)\n",
    "\n",
    "train(dataset, model, epochs, batch_size, seq_length)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['howdy', 'all', 'the', 'name', 'is', 'ken', 'meet', 'mine', 'range', 'but', 'probably', 'became', 'exceedingly', 'bitter', 'sinister', 'undeveloped', 'his', 'mind', 'code', 'marry', 'routine', 'indignation', 'punished', 'killing', 'absence', 'order', 'the', 'got', 'oregon', 'excite', 'wipe', 'guilty', 'climax', 'to', 'sheep', 'avidly', 'ruined', '``', 'ellen', 'stole', 'gift', 'dad', 'listen', \"'round\", '--', 'bear', 'old', 'young', 'red', 'he', 'ever', '--', 'died', '``', \"'wal\", 'jean', 'that', 'gunman', \"''\", 'said', '``', 'reckon', 'i', \"n't\", 'love', 'he', 'goin', 'n', '--', 'grievance', \"''\", '``', 'wal', 'rocky', 'ta', 'nez', 'meadow', \"''\", '``', 'how', '--', '--', 'stand', 'thet', 'u', \"''\", 'ejaculated', 'rancher', 'jean', '``', 'my', 'name', \"'s\", 'got', 'got', 'father', 'maskin', 'callin', \"''\", '``', 'where', \"''\", '``', 'bah', 'color', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "print(predict(dataset, model, text='howdy all the name is ken'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model-dict-slow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Model:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l3\", \"lstm.weight_hh_l3\", \"lstm.bias_ih_l3\", \"lstm.bias_hh_l3\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-47ccb644dfe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model-dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/3.0.0_1/libexec/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1224\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Model:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l3\", \"lstm.weight_hh_l3\", \"lstm.bias_ih_l3\", \"lstm.bias_hh_l3\". "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 256\n",
    "seq_length = 4\n",
    "\n",
    "dataset = Dataset(epochs, batch_size, seq_length)\n",
    "model2 = Model(dataset)\n",
    "model2.load_state_dict(torch.load('./model-dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./model-dict.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34434, 128])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([34434, 128])\n",
      "torch.Size([34434])\n"
     ]
    }
   ],
   "source": [
    "for key in checkpoint.keys():\n",
    "    print(checkpoint[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of Model(\n",
       "  (embedding): Embedding(34434, 128)\n",
       "  (lstm): LSTM(128, 128, num_layers=3, dropout=0.2)\n",
       "  (fc): Linear(in_features=128, out_features=34434, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.load('./model-dict12.pt',map_location=torch.device('cpu'))\n",
    "model2 = Model(dataset)\n",
    "model2.load_state_dict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shoot', 'the', 'dang', 'ol', 'rabbit', 'three', \"b'gosh\", 'danced', 'agony', 'cent', 'shone', 'motion', 'saddle', 'pulled', 'taken', 'flight', 'practicing', 'nurse', 'portion', 'clear', '...', 'all', 'from', 'ridge', 'earnest', 'established', 'somethin', 'requires', 'passionate', 'passage', 'dusty', 'convinced', 'another', 'weird', 'meet', 'snarled', 'ranch', 'spirit', 'strolled', 'gray', 'dying', 'told', 'left', 'quoted', 'till', 'i', 'felt', 'four', 'open', 'open', 'reflection', 'heart', 'some', 'i', 'astor', 'naab', 'money', 'sash', 'tickled', 'leaping', 'i', 'public', 'tribe', 'year', 'thank', 'around', 'darkness', 'turkey', 'without', '”', 'gang', 'circle', 'mouth', 'creamy', 'woman', 'vivacity', 'newcomer', 'along', 'upon', 'sorry', 'presently', 'big', 'hunt', 'something', 'believe', 'where', 'afternoon', 'indorsement', 'again', 'windfall', 'courage', 'brave', 'countenance', 'slope', 'thar', 'footprint', 'fur', 'refused', 'wind', 'tree', 'running', 'sure', 'hunter', 'anger', 'put']\n",
      "['shoot', 'the', 'dang', 'ol', 'rabbit', 'here', 'broken', 'burden', 'let', 'crag', 'swift', 'fashion', 'slim', 'hole', 'civility', 'i', 'i', 'crashed', 'branch', 'i', 'drive', 'indistinguishable', 'swift', 'cross', 'thing', 'sat', 'west', 'entering', 'garden', 'full', 'mebbe', 'water', 'hurry', 'canyon', '--', 'ranch', 'her', 'lee', 'beneath', 'first', 'she', 'labor', 'island', 'mescal', 'human', 'tree', 'ever', 'softened', 'see', 'time', 'quaking-asps', 'everywhere', 'aw', 'protested', 'drop', 'frying', 'excited', \"i'll\", 'the', 'leaped', 'hare', 'rankled', 'wo', 'married', 'already', 'and', 'hound', 'step', 'hash.', 'make', 'one', 'turned', 'bay', 'foot', 'resentment', \"''\", 'saw', 'union', 'shadow', 'leisurely', 'i', 'nervous', 'lift', 'piutes', 'low-voiced', 'pretty', 'happened', 'the', '”', 'mightily', 'plentifully', 'if', 'upon', 'made', 'corral', 'made', 'shaking', 'could', 'vanished', 'lie', 'climbed', 'upon', 'folded', 'warm', 'eye']\n",
      "['shoot', 'the', 'dang', 'ol', 'rabbit', 'allegiance', 'bow', 'he', 'low', 'red', 'moze', 'swelled', 'banged', 'brought', 'one', 'drawn', 'gray', 'next', 'gradual', 'around', 'morning', 'sens', 'story', 'turkey', 'entail', 'wretch', 'evening', 'i', 'that', 'sufficient', 'lass', 'handful', 'fight', 'sneak', 'overshadowing', 'valley', '--', 'burden', 'climbed', '....', 'second', 'packhorse', 'certain', 'giant', 'village', 'majesty', 'presenting', 'purple', 'next', 'sweep', 'discovery', 'sun', 'deputy', 'we', 'dreaming', 'kind', 'slope', 'rose', 'charged', \"father's\", 'scallywag', 'maddened', 'snow', 'empty-handed', 'clothes', 'shot', 'whispered', '--', 'next', 'repeated', '“', 'line', 'whang', 'went', '“', 'closed', 'indian', 'heard', 'abruptly', \"n't\", 'come', 'wide', 'hold', 'incommunicative', 'i', 'daylight', '--', 'ingenuity', 'leading', 'shorty', 'holding', 'find', 'matter', 'return', 'sweet', 'velvet', 'but', 'i', 'body', 'it', 'strength', 'called', 'particularly', 'happened', \"''\"]\n",
      "['shoot', 'the', 'dang', 'ol', 'rabbit', 'commodore', 'travel', 'steady', 'is', 'however', 'fatter', 'sharply', 'flaming', 'quieted', 'head', 'playing', 'muscular', 'open', 'elk', 'first', 'dropped', 'foot', 'sharp', 'ever', 'maybe', 'betty', 'west', 'border', 'ward', 'return', 'captured', 'bite', 'dream', 'mistake', 'lapsed', 'waiting', 'reared', 'missouri', 'surprise', 'duchess', 'catch', 'nearly', 'burlington', 'meet', 'gave', 'sun', 'i', 'usually', 'headed', 'passage', 'for', 'grew', 'her', 'seems', 'keep', 'danced', 'hour', 'get', 'like', 'monotone', 'darkness', '...', '“', 'awoke', 'long', 'far', 'orange', 'mule', 'several', 'drill', 'at', 'seemed', 'outcast', 'fix', 'made', 'gillivray', 'old', 'breast', 'seemed', 'tremendous', '...', 'i', 'many', 'would', 'sense', 'human', 'blossom', 'go', 'sometimes', 'slope', 'thet', 'desert', 'tie', 'flat', 'man', 'held', 'awoke', 'since', 'checked', 'let', 'figure', 'would', 'wet', 'listen', 'slowly']\n",
      "['shoot', 'the', 'dang', 'ol', 'rabbit', 'reproach', 'whispered', 'going', 'blind', 'sweet', 'hid', 'i', 'harry', 'voyage', 'i', 'toward', 'confounding', 'nervous', 'hunting', 'old', 'servant', 'everywhere', '``', 'mistaking', 'weird', 'best', 'weather', 'i', 'roof', 'excellent', 'navajo', 'driving', 'plump', 'progeny', 'butte', 'nearer', 'light', 'kill', 'south', 'life', 'gasp', 'pierced', 'away', 'where', 'interval', 'star', 'jones', 'somethin', 'many', 'big', 'sad', 'either', 'i', 'canyon', 'right', 'enjoyed', 'sympathy', 'gang', 'might', 'still', 'obsession', \"yu'\", 'm', 'the', 'edge', 'could', 'high', 'an', 'sleepy', 'listen', 'growing', 'look', 'wound', 'bank', 'cool', 'craggy', 'caucasian', 'mile', 'length', 'instant', 'hatin', 'definite', 'lookin', 'dealing', 'lost', 'talk', 'leaped', 'heard', 'backed', 'religion', 'slope', 'maybe', 'top', 'shook', 'footstep', 'brought', 'age', 'happened', 'uplifted', 'act', 'obeyed', 'strife', 'convulsive', 'lasso', 'let']\n",
      "['shoot', 'the', 'dang', 'ol', 'rabbit', 'attentively', 'leap', 'child', 'cruel', 'timber', 'he', 'face', 'swift', 'stubble', 'hardly', 'along', 'entered', 'ever', 'whispered', 'you', 'running', 'pole', \"'re\", 'illusion', 'favor', 'meat', 'maybe', 'soberly', 'wind', 'and', 'lay', 'hiding-place', 'proud', 'specie', 'he', 'sighted', 'reestablishment', 'overcome', 'compared', 'human', 'appeared', 'wind', 'i', 'ahead', 'nearer', 'snow', 'divided', 'seemed', 'bitterly', 'account', 'every', 'steele', 'painful', 'reach', 'mule', 'laughing', 'grasp', 'away', 'love', 'peak', 'fiddletown', 'indians', 'no', 'could', 'clearing', 'heard', 'unseen', 'law', 'dad', 'work', 'appearance', 'slope', 'gunshot', 'slope', 'gray', 'fired', 'pattern', 'then', \"''\", 'step', 'felt', 'east', 'deceive', 'rose', 'passing', 'horse-thief', 'he', 'lin', 'road', '“', 'company', 'wear', 'not', 'in', 'upon', 'man', 'are', 'january', 'almost', 'upon', 'running', 'when', 'gold', 'passed', 'argument']\n",
      "['shoot', 'the', 'dang', 'ol', 'rabbit', 'fixin', 'private', 'house', 'black', 'seeing', 'come', 'one', 'hard', 'strenuous', 'mescal', 'morning', 'pole', 'hour', 'drinking', 'back', 'the', 'hate', 'season', 'all', 'number', 'old', 'four', 'big', 'innkeeper', 'buy', 'freshened', 'gold', 'disappeared', 'indians', 'told', \"'em\", 'cried', 'disappointed', 'lip', 'i', 'nine', 'cinder', 'slowly', 'white', 'wall', \"i'd\", 'gettin', 'two', 'astoria', 'guilty', 'help', 'head', 'raised', 'wounded', 'line', 'hopelessly', 'operator', 'without', 'officer', 'he', 'clear', 'well', 'kept', \"'d\", 'little', 'break', 'sea', 'chance', 'clearing', 'long', 'voyage', 'even', \"'re\", 'toward', 'avalanche', 'yellow', 'beautiful', 'keen', 'texas', 'told', 'could', 'age', 'hear', 'end', 'cool', 'light', 'blossom', 'letting', 'four', 'fort', 'rim', 'canyon', 'tent', 'gray', 'located', 'rejected', 'dwell', 'stream', 'seemed', '--', 'saddle', 'sweep', 'thought', 'enough', 'singing']\n",
      "['shoot', 'the', 'dang', 'ol', 'rabbit', '“', 'different', 'going', 'hand', 'the', 'appearance', 'death', 'yes', 'thar', 'intimation', 'weapon', 'mustang', 'called', 'place', 'slid', 'suffered', 'a', 'future', 'inexplicable', 'mexican', 'fellow', 'light', 'top', 'usual', 'neck', 'snort', 'regarded', 'pack-train', 'remarked', 'i', 'image', 'saddled', 'distance', 'figure', 'hold', 'nearly', 'food', 'suggested', 'i', 'shadow', 'trade', \"'re\", 'don', 'sending', 'story', 'laugh', 'shore', 'unmix', 'timber', 'fay', 'forget', 'fiddletown', 'george', 'astoria', 'might', 'gold', 'awakened', 'point', 'game', 'disappeared', 'taxi', 'setting', 'sensitive', 'care', 'horseman', 'day', 'bear', 'bustle', 'white', 'knew', 'painted', 'kind', 'go', 'climbed', 'trail', 'horse', 'rang', 'wagon', 'hurt', 'watching', 'broken', 'ran', 'misspelled', 'life', 'behind', 'swiftly', 'long', 'drink', 'wind', 'another', 'improved', 'terribly', 'i', 'slope', 'looked', 'tonto', \"'could\", 'begged', 'night', 'i']\n",
      "['shoot', 'the', 'dang', 'ol', 'rabbit', 'sprawled', 'subtly', 'hollow', 'menaced', 'agitation', 'pointing', 'a', 'youth', 'remember', 'strong', 'they', \"'d\", 'blue', 'never', \"'s\", 'west', 'reached', 'from', 'suit', 'smile', 'brief', 'freed', 'matter', 'i', 'relief', 'and', 'we', 'they', 'field', '“', 'straggler', 'behind', 'youngster', 'burst', 'affinity', 'best', 'shadow', 'i', 'ride', 'would', 'throw', 'las', 'it', 'came', 'seven', 'could', 'bold', 'it', 'narrow', 'green', 'prepared', 'middle', 'cow-puncher', 'anger', 'one', 'made', 'snort', 'winter', 'wild', 'tall', 'restless', \"n't\", 'glade', 'i', 'kept', 'little', 'then', 'feelin', 'part', 'hopeless', 'clear', '“', 'struggled', 'at', 'instant', 'honor', 'rained', 'see', 'oar', 'sun', 'asleep', 'din', 'cracked', '``', 'place', 'joy', 'gentleman', 'one', 'showed', 'huge', 'head', 'i', 'feeling', 'beneath', 'calculated', 'mine', 'plain', 'high', 'lasso', 'meat']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shoot', 'the', 'dang', 'ol', 'rabbit', 'gauged', 'eye', 'time', 'whip', 'gentleman', 'leaving', 'all', 'lingered', 'fell', 'evidently', \"'s\", 'corpse', 'way', 'sight', 'appeared', 'see', 'edge', 'jones', 'constantly', 'could', 'several', 'another', '“', 'cut', 'track', 'gaining', 'case', \"'s\", 'circumstance', 'fast', 'pale', 'unreal', 'giant', 'disarmed', 'like', 'expects', 'whispered', 'pistol', 'continued', 'mounting', 'trotted', 'withers', 'aftermath', 'repair', '``', 'managed', 'see', 'first', 'colder', 'progress', '--', 'big', '....', 'header', 'wreck', 'justice', 'ai', 'frigid', 'race', 'hand', 'space', 'crossed', 'but', 'wave', 'concerning', 'every', 'spectre', 'saw', 'irresistibly', 'dust', 'heat', 'inheritor', 'long', 'upon', 'stroke', 'close', 'shouted', 'escape', 'herbage', 'hunter', 'spot', 'running', 'existed', 'expect', 'labored', 'but', 'quiet', 'states', 'screen', 'slipped', \"'ll\", 'slightest', 'life', 'discharged', 'go', 'soft', 'mustang', 'rock', 'left', 'sixty']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(predict(dataset, model2, text='shoot the dang ol rabbit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
