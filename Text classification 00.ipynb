{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally following:<br>\n",
    "https://medium.com/data-from-the-trenches/text-classification-the-first-step-toward-nlp-mastery-f5f95d525d73<br>\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import re\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = glob.glob('C:\\\\UT\\\\DataMining\\\\books\\\\set0\\\\*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unreadable character in western15.txt gave me trouble, so I renamed it western15.txt5<br>\n",
    "so it wouldn't get included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 9\n",
    "mstr = '\\\\'\n",
    "train_texts = []\n",
    "test_texts = []\n",
    "train_cats = []\n",
    "test_cats = []\n",
    "for file in text_files:\n",
    "    fileNum = int(file[-6:-4])\n",
    "    v = file.rfind(mstr) + len(mstr)\n",
    "    fileCat = file[v:-6]\n",
    "    if (fileNum <= cutoff):\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            train_texts.append(text)\n",
    "            train_cats.append(fileCat)\n",
    "    else:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            test_texts.append(text)\n",
    "            test_cats.append(fileCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 55\n",
      "68 55\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts), len(test_texts))\n",
    "print(len(train_cats), len(test_cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(np.array(train_texts))\n",
    "df_train['Category'] = train_cats\n",
    "df_train.columns = [\"text\", \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿The Project Gutenberg eBook of The Count of M...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿\\nThe Project Gutenberg EBook of The Call of ...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>﻿The Project Gutenberg EBook of Around the Wor...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿The Project Gutenberg eBook, White Fang, by J...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>﻿                          THE THREE MUSKETEER...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   category\n",
       "0  ﻿The Project Gutenberg eBook of The Count of M...  adventure\n",
       "1  ﻿\\nThe Project Gutenberg EBook of The Call of ...  adventure\n",
       "2  ﻿The Project Gutenberg EBook of Around the Wor...  adventure\n",
       "3  ﻿The Project Gutenberg eBook, White Fang, by J...  adventure\n",
       "4  ﻿                          THE THREE MUSKETEER...  adventure"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(np.array(test_texts))\n",
    "df_test['Category'] = test_cats\n",
    "df_test.columns = [\"text\", \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿The Project Gutenberg EBook of King Solomon's...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿The Project Gutenberg eBook of Moby-Dick, by ...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>﻿The Project Gutenberg EBook of The Prisoner o...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿The Project Gutenberg eBook of She, by H. Rid...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>﻿Project Gutenberg’s The Man in the Iron Mask,...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   category\n",
       "0  ﻿The Project Gutenberg EBook of King Solomon's...  adventure\n",
       "1  ﻿The Project Gutenberg eBook of Moby-Dick, by ...  adventure\n",
       "2  ﻿The Project Gutenberg EBook of The Prisoner o...  adventure\n",
       "3  ﻿The Project Gutenberg eBook of She, by H. Rid...  adventure\n",
       "4  ﻿Project Gutenberg’s The Man in the Iron Mask,...  adventure"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies some pre-processing on the given text.\n",
    "\n",
    "    Steps :\n",
    "    - Removing HTML tags\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)\n",
    "    \n",
    "    # remove numbers including unsigned / signed integers and floats\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    text = re.sub(r\"[-0-9]+\", \"\", text)\n",
    "    text = re.sub(r\"[+.0-9]+\", \"\", text)\n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    \n",
    "    # remove non-ascii characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+','', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.36\n"
     ]
    }
   ],
   "source": [
    "# Transform each text into a vector of word counts\n",
    "# CountVectorizer calls preprocessor, filters stopwords, and tokenizes to sparse matrix\n",
    "# \"Count\" is a crude metric since longer books will naturally have more words\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             strip_accents=\"ascii\")\n",
    "\n",
    "train_features = vectorizer.fit_transform(df_train[\"text\"])    \n",
    "test_features = vectorizer.transform(df_test[\"text\"])\n",
    "\n",
    "# Training\n",
    "model = LinearSVC()\n",
    "model.fit(train_features, df_train[\"category\"])\n",
    "y_pred_0 = model.predict(test_features)\n",
    "\n",
    "# Evaluation\n",
    "acc = accuracy_score(df_test[\"category\"], y_pred_0)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95014\n"
     ]
    }
   ],
   "source": [
    "#dictionary of feature indices, it's length is the number of features (words) in the data set\n",
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with ngram: 58.18\n"
     ]
    }
   ],
   "source": [
    "# Transform each text into a vector of word counts\n",
    "# TF (Term Frequency) times IDF (Inverse Document Frequency) is better than a count vectorizer\n",
    "# TF measures words by frequency to normalize for book length\n",
    "# IDF reduces the weight of words that appear in many documents\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2))\n",
    "\n",
    "train_features = vectorizer.fit_transform(df_train[\"text\"])\n",
    "test_features = vectorizer.transform(df_test[\"text\"])\n",
    "\n",
    "# Training\n",
    "model = LinearSVC()\n",
    "model.fit(train_features, df_train[\"category\"])\n",
    "y_pred_1 = model.predict(test_features)\n",
    "\n",
    "# Evaluation\n",
    "acc = accuracy_score(df_test[\"category\"], y_pred_1)\n",
    "\n",
    "print(\"Accuracy with ngram: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True         Predicted1   Predicted2   Predicted4  \n",
      "----         ----------   ----------   ----------  \n",
      "adventure    adventure    adventure    adventure   \n",
      "adventure    adventure    scifi        adventure   \n",
      "adventure    humor        adventure    adventure   \n",
      "adventure    gothic       adventure    gothic      \n",
      "adventure    adventure    adventure    adventure   \n",
      "adventure    adventure    adventure    adventure   \n",
      "adventure    adventure    adventure    adventure   \n",
      "adventure    humor        adventure    adventure   \n",
      "adventure    gothic       adventure    adventure   \n",
      "adventure    mystery      adventure    adventure   \n",
      "gothic       mystery      gothic       gothic      \n",
      "gothic       horror       horror       horror      \n",
      "gothic       horror       horror       horror      \n",
      "gothic       mystery      mystery      horror      \n",
      "gothic       adventure    adventure    adventure   \n",
      "gothic       gothic       gothic       gothic      \n",
      "horror       scifi        western      scifi       \n",
      "horror       scifi        scifi        scifi       \n",
      "horror       horror       mystery      horror      \n",
      "horror       horror       horror       horror      \n",
      "horror       scifi        humor        scifi       \n",
      "horror       scifi        adventure    gothic      \n",
      "horror       scifi        humor        scifi       \n",
      "horror       scifi        scifi        scifi       \n",
      "horror       humor        gothic       gothic      \n",
      "horror       horror       gothic       gothic      \n",
      "humor        gothic       mystery      gothic      \n",
      "humor        humor        humor        humor       \n",
      "humor        humor        humor        humor       \n",
      "humor        humor        humor        humor       \n",
      "humor        humor        humor        humor       \n",
      "humor        adventure    humor        humor       \n",
      "humor        humor        mystery      gothic      \n",
      "humor        humor        humor        humor       \n",
      "humor        scifi        humor        horror      \n",
      "humor        humor        humor        humor       \n",
      "scifi        scifi        scifi        scifi       \n",
      "scifi        scifi        scifi        scifi       \n",
      "scifi        humor        gothic       gothic      \n",
      "scifi        scifi        humor        scifi       \n",
      "scifi        scifi        humor        scifi       \n",
      "scifi        scifi        scifi        scifi       \n",
      "scifi        scifi        scifi        scifi       \n",
      "scifi        scifi        scifi        scifi       \n",
      "scifi        scifi        humor        scifi       \n",
      "scifi        scifi        scifi        scifi       \n",
      "western      western      western      western     \n",
      "western      humor        western      western     \n",
      "western      western      western      western     \n",
      "western      western      western      western     \n",
      "western      western      western      western     \n",
      "western      adventure    western      western     \n",
      "western      western      western      western     \n",
      "western      western      western      western     \n",
      "western      western      western      western     \n"
     ]
    }
   ],
   "source": [
    "print('{0:<12} {1:<12} {2:<12} {3:<12}'.format(\"True\", \"Predicted1\", \"Predicted2\", \"Predicted4\"))\n",
    "print('{0:<12} {1:<12} {2:<12} {3:<12}'.format(\"----\", \"----------\",\"----------\", \"----------\"))\n",
    "for i in range(len(y_pred_2)):\n",
    "    print('{0:<12} {1:<12} {2:<12} {3:<12}'.format(df_test[\"category\"][i], y_pred_1[i], y_pred_2[i], y_pred_4[i]))\n",
    "    #print(df_test[\"category\"][i], y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 3, 1, 1, 0, 0],\n",
       "       [0, 2, 3, 0, 1, 0, 0],\n",
       "       [0, 0, 4, 1, 0, 5, 0],\n",
       "       [1, 2, 1, 5, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 8, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 7]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_test[\"category\"], y_pred_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2, 0, 2, 1, 0, 0],\n",
       "       [1, 1, 2, 0, 2, 0, 0],\n",
       "       [0, 0, 3, 1, 0, 6, 0],\n",
       "       [1, 1, 0, 7, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 9, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 7]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_test[\"category\"], y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with ngram: 63.64\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train_features, df_train[\"category\"])\n",
    "y_pred_2 = clf.predict(test_features)\n",
    "\n",
    "# Evaluation\n",
    "acc = accuracy_score(df_test[\"category\"], y_pred_2)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                         alpha=1e-3, random_state=42,\n",
    "                         max_iter=5, tol=None)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 27.27\n"
     ]
    }
   ],
   "source": [
    "text_clf.fit(df_train[\"text\"], df_train[\"category\"])\n",
    "y_pred_3 = text_clf.predict(df_test[\"text\"])\n",
    "\n",
    "# Evaluation\n",
    "acc = accuracy_score(df_test[\"category\"], y_pred_3)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   adventure       0.24      1.00      0.39        10\n",
      "      gothic       0.00      0.00      0.00         6\n",
      "      horror       0.00      0.00      0.00        10\n",
      "       humor       0.50      0.10      0.17        10\n",
      "     mystery       0.00      0.00      0.00         0\n",
      "       scifi       1.00      0.10      0.18        10\n",
      "     western       0.50      0.33      0.40         9\n",
      "\n",
      "    accuracy                           0.27        55\n",
      "   macro avg       0.32      0.22      0.16        55\n",
      "weighted avg       0.40      0.27      0.20        55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clayj\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\clayj\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test[\"category\"], y_pred_3))c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(df_train[\"text\"], df_train[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_nb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__fit_prior': (True, False),\n",
    "    'clf__alpha': (0, 1e-2, 1e-3, 0.5, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf_nb = GridSearchCV(text_clf_nb, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf_nb = gs_clf_nb.fit(df_train[\"text\"], df_train[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'clf__fit_prior': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf_nb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters:<br>\n",
    "{'clf__alpha': 0.001, 'clf__fit_prior': True, 'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_best = gs_clf_nb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.09\n"
     ]
    }
   ],
   "source": [
    "y_pred_4 = nb_best.predict(df_test[\"text\"])\n",
    "\n",
    "# Evaluation\n",
    "acc = accuracy_score(df_test[\"category\"], y_pred_4)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   adventure       0.90      0.90      0.90        10\n",
      "      gothic       0.22      0.33      0.27         6\n",
      "      horror       0.33      0.20      0.25        10\n",
      "       humor       1.00      0.70      0.82        10\n",
      "       scifi       0.64      0.90      0.75        10\n",
      "     western       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.69        55\n",
      "   macro avg       0.68      0.67      0.67        55\n",
      "weighted avg       0.71      0.69      0.69        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test[\"category\"], y_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                pred:adventure  pred:gothic  pred:horror  pred:humor  \\\n",
      "true:adventure               9            1            0           0   \n",
      "true:gothic                  1            2            3           0   \n",
      "true:horror                  0            3            2           0   \n",
      "true:humor                   0            2            1           7   \n",
      "true:scifi                   0            1            0           0   \n",
      "true:western                 0            0            0           0   \n",
      "\n",
      "                pred:scifi  pred:western  \n",
      "true:adventure           0             0  \n",
      "true:gothic              0             0  \n",
      "true:horror              5             0  \n",
      "true:humor               0             0  \n",
      "true:scifi               9             0  \n",
      "true:western             0             9  \n"
     ]
    }
   ],
   "source": [
    "unique_label = list(df_test[\"category\"].unique())\n",
    "cmtx = pd.DataFrame(confusion_matrix(df_test[\"category\"], y_pred_4, labels= unique_label),\n",
    "                    index=['true:{:}'.format(x) for x in unique_label], \n",
    "                    columns=['pred:{:}'.format(x) for x in unique_label])\n",
    "print(cmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
